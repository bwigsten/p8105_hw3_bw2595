p8105\_hw3\_bw2595
================
Blair Wigsten
10/8/2019

``` r
library(tidyverse)
```

    ## ── Attaching packages ──────────────────────────────────────────────────── tidyverse 1.2.1 ──

    ## ✔ ggplot2 3.2.1     ✔ purrr   0.3.2
    ## ✔ tibble  2.1.3     ✔ dplyr   0.8.3
    ## ✔ tidyr   1.0.0     ✔ stringr 1.4.0
    ## ✔ readr   1.3.1     ✔ forcats 0.4.0

    ## ── Conflicts ─────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(knitr)
```

``` r
library(p8105.datasets)
data("instacart")
instacart
```

    ## # A tibble: 1,384,617 x 15
    ##    order_id product_id add_to_cart_ord… reordered user_id eval_set
    ##       <int>      <int>            <int>     <int>   <int> <chr>   
    ##  1        1      49302                1         1  112108 train   
    ##  2        1      11109                2         1  112108 train   
    ##  3        1      10246                3         0  112108 train   
    ##  4        1      49683                4         0  112108 train   
    ##  5        1      43633                5         1  112108 train   
    ##  6        1      13176                6         0  112108 train   
    ##  7        1      47209                7         0  112108 train   
    ##  8        1      22035                8         1  112108 train   
    ##  9       36      39612                1         0   79431 train   
    ## 10       36      19660                2         1   79431 train   
    ## # … with 1,384,607 more rows, and 9 more variables: order_number <int>,
    ## #   order_dow <int>, order_hour_of_day <int>,
    ## #   days_since_prior_order <int>, product_name <chr>, aisle_id <int>,
    ## #   department_id <int>, aisle <chr>, department <chr>

There are 1,384,617 observations and 15 variables in the instacart
dataset. Most variables are integer variables, with the rest (eval\_set,
product\_name, aisle, and department) as character variables. *key
variables *illustrative examples

``` r
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # … with 124 more rows

There are 134 distinct aisles, with “fresh vegetables”, “fresh fruits”,
and “packaged vegetables and fruits” are where most items are ordered
from based on the table produced above.

``` r
items_plot = instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  rename(n_items_ordered = n) %>%
  ggplot(aes(x = reorder(aisle, -n_items_ordered), y = n_items_ordered)) +
    geom_bar(stat = "identity") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
    labs(
    title = "Number of items ordered per aisle",
    x = "aisle name",
    y = "number of items ordered"
    )
items_plot
```

![](p8105_hw3_bw2595_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

Make a table showing the three most popular items in each of the aisles
“baking ingredients”, “dog food care”, and “packaged vegetables
fruits”. Include the number of times each item is ordered in your
table.

``` r
popular_product = instacart %>%
  group_by(product_name, aisle) %>%
  summarize(
    n_ordered = n()) %>%
  group_by(aisle) %>%
  filter(
    aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits"), 
    min_rank(desc(n_ordered)) < 4) %>%
  arrange(n_ordered, aisle) %>%
  kable(format = "pandoc", caption = "Most popular items by aisle")
popular_product
```

| product\_name                                 | aisle                      | n\_ordered |
| :-------------------------------------------- | :------------------------- | ---------: |
| Small Dog Biscuits                            | dog food care              |         26 |
| Organix Chicken & Brown Rice Recipe           | dog food care              |         28 |
| Snack Sticks Chicken & Rice Recipe Dog Treats | dog food care              |         30 |
| Cane Sugar                                    | baking ingredients         |        336 |
| Pure Baking Soda                              | baking ingredients         |        387 |
| Light Brown Sugar                             | baking ingredients         |        499 |
| Organic Blueberries                           | packaged vegetables fruits |       4966 |
| Organic Raspberries                           | packaged vegetables fruits |       5546 |
| Organic Baby Spinach                          | packaged vegetables fruits |       9784 |

Most popular items by aisle

Make a table showing the mean hour of the day at which Pink Lady Apples
and Coffee Ice Cream are ordered on each day of the week; format this
table for human readers (i.e. produce a 2 x 7 table).

``` r
apples_cream = instacart %>%
  rename(order_hour = order_hour_of_day) %>%
  select(product_name, order_dow, order_hour) %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(
    mean_hour_of_day = mean(order_hour)) %>%
  mutate(
    day_of_week = recode(order_dow,
                         `0` = "Sunday", 
                         `1` = "Monday",
                         `2` = "Tuesday",
                         `3` = "Wednesday",
                         `4` = "Thursday",
                         `5` = "Friday",
                         `6` = "Saturday")) %>%
  select(product_name, day_of_week, mean_hour_of_day) %>%
  pivot_wider(
    names_from = "product_name",
    values_from = "mean_hour_of_day") %>%
  kable(format = "pandoc", caption = "Mean Hour of Pink Lady Apples and Coffee Ice Cream Orders")
apples_cream
```

| day\_of\_week | Coffee Ice Cream | Pink Lady Apples |
| :------------ | ---------------: | ---------------: |
| Sunday        |         13.77419 |         13.44118 |
| Monday        |         14.31579 |         11.36000 |
| Tuesday       |         15.38095 |         11.70213 |
| Wednesday     |         15.31818 |         14.25000 |
| Thursday      |         15.21739 |         11.55172 |
| Friday        |         12.26316 |         12.78431 |
| Saturday      |         13.83333 |         11.93750 |

Mean Hour of Pink Lady Apples and Coffee Ice Cream Orders

``` r
library(p8105.datasets)
data("brfss_smart2010")
brfss_smart2010
```

    ## # A tibble: 134,203 x 23
    ##     Year Locationabbr Locationdesc Class Topic Question Response
    ##    <int> <chr>        <chr>        <chr> <chr> <chr>    <chr>   
    ##  1  2010 AL           AL - Jeffer… Heal… Over… How is … Excelle…
    ##  2  2010 AL           AL - Jeffer… Heal… Over… How is … Very go…
    ##  3  2010 AL           AL - Jeffer… Heal… Over… How is … Good    
    ##  4  2010 AL           AL - Jeffer… Heal… Over… How is … Fair    
    ##  5  2010 AL           AL - Jeffer… Heal… Over… How is … Poor    
    ##  6  2010 AL           AL - Jeffer… Heal… Fair… Health … Good or…
    ##  7  2010 AL           AL - Jeffer… Heal… Fair… Health … Fair or…
    ##  8  2010 AL           AL - Jeffer… Heal… Heal… Do you … Yes     
    ##  9  2010 AL           AL - Jeffer… Heal… Heal… Do you … No      
    ## 10  2010 AL           AL - Jeffer… Heal… Unde… Adults … Yes     
    ## # … with 134,193 more rows, and 16 more variables: Sample_Size <int>,
    ## #   Data_value <dbl>, Confidence_limit_Low <dbl>,
    ## #   Confidence_limit_High <dbl>, Display_order <int>,
    ## #   Data_value_unit <chr>, Data_value_type <chr>,
    ## #   Data_Value_Footnote_Symbol <chr>, Data_Value_Footnote <chr>,
    ## #   DataSource <chr>, ClassId <chr>, TopicId <chr>, LocationID <chr>,
    ## #   QuestionID <chr>, RESPID <chr>, GeoLocation <chr>

format the data to use appropriate variable names; focus on the “Overall
Health” topic include only responses from “Excellent” to “Poor” organize
responses as a factor taking levels ordered from “Poor” to “Excellent”

``` r
response_table = brfss_smart2010 %>%
  filter(Topic == "Overall Health") %>%
  count(Response)
response_table
```

    ## # A tibble: 5 x 2
    ##   Response      n
    ##   <chr>     <int>
    ## 1 Excellent  2125
    ## 2 Fair       2125
    ## 3 Good       2125
    ## 4 Poor       2125
    ## 5 Very good  2125

responses are already in the range of “Excellent” to “Poor”, taking on
values of “Excellent”, “Very good”, “Good”, “Fair”, and “Poor”.

``` r
brfss = brfss_smart2010 %>%
  janitor::clean_names() %>%
  rename(
    state = locationabbr, 
    county = locationdesc,
    lcl = confidence_limit_low,
    ucl = confidence_limit_high) %>%
  filter(topic == "Overall Health") %>%
  mutate(response = factor(response, c("Poor", "Fair", "Good", "Very good", "Excellent")))
brfss
```

    ## # A tibble: 10,625 x 23
    ##     year state county class topic question response sample_size data_value
    ##    <int> <chr> <chr>  <chr> <chr> <chr>    <fct>          <int>      <dbl>
    ##  1  2010 AL    AL - … Heal… Over… How is … Excelle…          94       18.9
    ##  2  2010 AL    AL - … Heal… Over… How is … Very go…         148       30  
    ##  3  2010 AL    AL - … Heal… Over… How is … Good             208       33.1
    ##  4  2010 AL    AL - … Heal… Over… How is … Fair             107       12.5
    ##  5  2010 AL    AL - … Heal… Over… How is … Poor              45        5.5
    ##  6  2010 AL    AL - … Heal… Over… How is … Excelle…          91       15.6
    ##  7  2010 AL    AL - … Heal… Over… How is … Very go…         177       31.3
    ##  8  2010 AL    AL - … Heal… Over… How is … Good             224       31.2
    ##  9  2010 AL    AL - … Heal… Over… How is … Fair             120       15.5
    ## 10  2010 AL    AL - … Heal… Over… How is … Poor              66        6.4
    ## # … with 10,615 more rows, and 14 more variables: lcl <dbl>, ucl <dbl>,
    ## #   display_order <int>, data_value_unit <chr>, data_value_type <chr>,
    ## #   data_value_footnote_symbol <chr>, data_value_footnote <chr>,
    ## #   data_source <chr>, class_id <chr>, topic_id <chr>, location_id <chr>,
    ## #   question_id <chr>, respid <chr>, geo_location <chr>

In 2002, which states were observed at 7 or more locations? What about
in 2010?

``` r
brfss1 = brfss %>% 
  filter(year == "2002") %>%
  separate(county, into = c("states", "county")) %>%
  group_by(state) %>%
  filter(n() >= 7) %>%
  distinct(state, county)
```

    ## Warning: Expected 2 pieces. Additional pieces discarded in 785 rows [1, 2,
    ## 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].

``` r
brfss1 %>%
  count(state) %>%
  filter(n >= 7) %>%
  rename(number_observations = n) 
```

    ## # A tibble: 5 x 2
    ## # Groups:   state [5]
    ##   state number_observations
    ##   <chr>               <int>
    ## 1 FL                      7
    ## 2 MA                      8
    ## 3 NC                      7
    ## 4 NJ                      8
    ## 5 PA                     10

``` r
brfss2 = brfss %>% 
  filter(year == "2010") %>%
  separate(county, into = c("states", "county")) %>%
  group_by(state) %>%
  filter(n() >= 7) %>%
  distinct(state, county)
```

    ## Warning: Expected 2 pieces. Additional pieces discarded in 1510 rows [1, 2,
    ## 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].

``` r
brfss2 %>%
  count(state) %>%
  filter(n >= 7) %>%
  rename(number_observations = n) 
```

    ## # A tibble: 14 x 2
    ## # Groups:   state [14]
    ##    state number_observations
    ##    <chr>               <int>
    ##  1 CA                      9
    ##  2 CO                      7
    ##  3 FL                     40
    ##  4 MA                      9
    ##  5 MD                     11
    ##  6 NC                     12
    ##  7 NE                     10
    ##  8 NJ                     19
    ##  9 NY                      9
    ## 10 OH                      8
    ## 11 PA                      7
    ## 12 SC                      7
    ## 13 TX                     16
    ## 14 WA                     10

In 2002, there were 5 states which had 7 or more observation sites
(counties), shown in the first table above. In 2010, there were 14
states which had 7 or more observations sites (counties), shown in the
second table above.
